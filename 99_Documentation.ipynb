{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environnement d'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm     as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri    as tri\n",
    "import numpy             as np\n",
    "import os\n",
    "import scipy.stats       as scs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions génériques de traitement d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(img: np.ndarray) -> np.ndarray:\n",
    "    img_ = np.fft.fft2(img)\n",
    "    img_ = np.power(np.abs(img_), 2)\n",
    "    img_ = np.fft.ifft2(img_)\n",
    "    img_ = np.abs(np.fft.fftshift(img_)/np.nanmax(img_))\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cinfinity(img: np.ndarray) -> float:\n",
    "    cinf = np.power(img.mean(), 2) /np.power(img, 2).mean()\n",
    "    return cinf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequences(img: np.ndarray, shift=False) -> np.ndarray:\n",
    "    img_ = np.fft.fft2(img)\n",
    "    if shift: img_ = np.fft.fftshift(img_)\n",
    "    img_ = np.abs(img_)\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial(img: np.ndarray, shift=False) -> np.ndarray:\n",
    "    img_ = np.fft.ifft2(img)\n",
    "    if shift: img_ = np.fft.fftshift(img_)\n",
    "    img_ = np.abs(img_)\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(img: np.ndarray, theta: float) -> tuple:\n",
    "\n",
    "    while theta > 2*np.pi:\n",
    "        theta -= 2*np.pi\n",
    "    \n",
    "    while theta < 2*np.pi:\n",
    "        theta += 2*np.pi\n",
    "\n",
    "    if theta > np.pi:\n",
    "        theta -= np.pi\n",
    "\n",
    "    ny, nx = img.shape\n",
    "    \n",
    "    j_ = np.linspace(0, nx//2-1, nx//2).astype(np.int32)\n",
    "    i_ = np.round(j_ *np.tan(theta)).astype(np.int32)\n",
    "\n",
    "    j_ = j_[np.abs(i_) < ny//2]\n",
    "    i_ = i_[np.abs(i_) < ny//2]\n",
    "\n",
    "    radius = np.sqrt( np.power(i_, 2) + np.power(j_, 2) )\n",
    "\n",
    "    if theta < np.pi/2:\n",
    "        values = img[ny//2-i_, nx//2+j_]\n",
    "    else:\n",
    "        values = img[ny//2-i_, nx//2-j_]\n",
    "\n",
    "    return (radius, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour(img: np.ndarray, cinf: float) -> tuple:\n",
    "\n",
    "    ny, nx = img.shape\n",
    "    \n",
    "    angles = np.linspace(0, 179, 180).astype(np.int32)\n",
    "    radius = np.zeros_like(angles, dtype=np.float64)\n",
    "\n",
    "    j_ = np.linspace(0, nx//2-1, nx//2).astype(np.int32)\n",
    "\n",
    "    for k, angle in enumerate(angles):\n",
    "        \n",
    "        if angle == 90:\n",
    "            radius[k] = radius[k-1]\n",
    "            continue\n",
    "\n",
    "        i_ = np.round(j_ *np.tan(angle*np.pi/180)).astype(np.int32)\n",
    "        j_ = j_[np.abs(i_) < ny//2]\n",
    "        i_ = i_[np.abs(i_) < ny//2]\n",
    "\n",
    "        radius[k] = np.sqrt( i_[-1]**2 + j_[-1]**2 )\n",
    "        \n",
    "        if angle < 90:\n",
    "            for (i, j) in zip(i_,j_):\n",
    "                if img[ny//2-i,nx//2+j] > cinf:\n",
    "                    continue\n",
    "                else:\n",
    "                    radius[k] = np.sqrt( i**2 + j**2 )\n",
    "                    break\n",
    "        \n",
    "        else:\n",
    "            for (i, j) in zip(i_,j_):\n",
    "                if img[ny//2-i,nx//2-j] >= cinf:\n",
    "                    continue\n",
    "                else:\n",
    "                    radius[k] = np.sqrt( i**2 + j**2 )\n",
    "                    break\n",
    "\n",
    "    return (angles, radius)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions d'affichage génériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation d'une expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience():\n",
    "\n",
    "    def __init__(self, infile: str, outfolder: str = \"\"):\n",
    "        \"\"\"\n",
    "        Constructeur.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        infile    : str\n",
    "                    lien absolu vers le fichier .csv contenant les données de l'expérience.\n",
    "        outfolder : str (optional)\n",
    "                    lien absolu vers le dossier dans lequel doit être enregistré le résultat de l'analyse.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        \"\"\"\n",
    "        self.path = infile\n",
    "        self.outfolder = outfolder\n",
    "        self.__read()\n",
    "        self.__clean()\n",
    "        self.__filter()\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    def __read(self):\n",
    "        \"\"\"\n",
    "        Lecture du fichier .csv et paramétrage des attributs représentant la taille de l'image.\n",
    "        \"\"\"\n",
    "        self.data = np.genfromtxt( self.path, delimiter=\",\", dtype=np.float64 )\n",
    "        self.ny, self.nx = self.data.shape\n",
    "        return\n",
    "    \n",
    "\n",
    "    def __clean(self):\n",
    "        \"\"\"\n",
    "        Remplissage des NaNs détectés après la lecture. On remplit automatiquement par la moyenne.\n",
    "        \"\"\"\n",
    "        self.data = np.nan_to_num(self.data, nan=np.nanmean(self.data))\n",
    "        return\n",
    "    \n",
    "\n",
    "    def __filter(self):\n",
    "        \"\"\"\n",
    "        Transformation d'une partie du spectre de l'image.\n",
    "        \"\"\"\n",
    "        self.img = frequences(self.data, shift=True)\n",
    "        self.img[:,self.nx//2] = np.power(self.img[:,self.nx//2], 0.5)\n",
    "        self.img = spatial(self.img, shift=False)\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def analyse(self):\n",
    "        \n",
    "        self.describe(self.outfolder)\n",
    "        \n",
    "        nrows = 1\n",
    "        ncols = 4\n",
    "        fig = plt.figure(figsize=(nrows*40, ncols*(8+0.5)))\n",
    "\n",
    "        axe = fig.add_subplot(nrows, ncols, 1)\n",
    "        axe.imshow(self.data, origin=\"lower\")\n",
    "        axe.set_title(\"$E_{yy}$\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "\n",
    "\n",
    "        freqs = frequences(self.data)\n",
    "\n",
    "        axe = fig.add_subplot(nrows, ncols, 2)\n",
    "        axe.imshow(np.log(freqs), origin=\"lower\")\n",
    "        axe.set_title(\"$\\log(\\mathcal{F}(E_{yy}))$\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "\n",
    "\n",
    "        axe = fig.add_subplot(nrows, ncols, 3)\n",
    "        axe.imshow(np.log(self.img), origin=\"lower\")\n",
    "        axe.set_title(\"$\\log(\\mathcal{T}(E_{yy}))$\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "\n",
    "\n",
    "        autocor = autocorrelation(self.img)\n",
    "        cinf    = cinfinity(self.data)\n",
    "\n",
    "        axe = fig.add_subplot(nrows, ncols, 4)\n",
    "        # axe.imshow(np.log(autocor/cinf), origin='lower')\n",
    "        # axe.contour(np.log(autocor/cinf), [0.0, (autocor/cinf).max()], cmap=cm.jet)\n",
    "        axe.imshow(autocor, origin='lower')\n",
    "        axe.contour(autocor, [cinf, autocor.max()], cmap=cm.jet)\n",
    "        # axe.set_title(\"$\\log\\left(\\\\frac{\\mathcal{A}(E_{yy})}{C_\\infty}\\\\right)$\")\n",
    "        axe.set_title(\"$\\mathcal{A}(E_{yy})$\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "\n",
    "        plt.suptitle(f\"{os.path.basename(self.path)}\", fontsize=40)\n",
    "\n",
    "        if self.outfolder == \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(f\"{self.outfolder}/{os.path.basename(self.path)}_autocorrelation.jpg\")\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        angles, radius = contour(autocor, cinf)\n",
    "\n",
    "        axe = fig.add_subplot(1,1,1)\n",
    "        axe.plot(angles, radius)\n",
    "        axe.set_title(\"Distance au contour en fonction de la direction\")\n",
    "        axe.set_xlabel(\"Angle [°]\")\n",
    "        axe.set_xlim(left=0, right=180)\n",
    "        axe.set_ylabel(\"Radius to $C_\\infty$ [px]\")\n",
    "        axe.set_ylim(bottom=0, top=radius.max())\n",
    "\n",
    "        if self.outfolder == \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(f\"{self.outfolder}/{os.path.basename(self.path)}_radius_vs_angle.jpg\")\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def describe(self):\n",
    "        if self.outfolder == \"\":\n",
    "            print(f\"Data description :\")\n",
    "            print(f\"------------------\")\n",
    "            print(f\"dimension : {self.data.ndim}\")\n",
    "            print(f\"shape     : {self.data.shape}\")\n",
    "            print(f\"NaNs      : {np.any(np.isnan(self.data))}\")\n",
    "            print(f\"mean      : {np.nanmean(self.data)}\")\n",
    "            print(f\"std       : {np.nanstd(self.data)}\")\n",
    "            print(f\"min       : {np.nanmin(self.data)}\")\n",
    "            print(f\"max       : {np.nanmax(self.data)}\")\n",
    "            print(f\"kurtosis  : {scs.kurtosis(self.data.flatten(), fisher=True, nan_policy='omit')}\")\n",
    "            print(f\"skewness  : {scs.skew(self.data.flatten(), nan_policy='omit')}\")\n",
    "            print(f\"C_inf     : {cinfinity(self.data)}\")\n",
    "            print()\n",
    "            print(f\"Image description :\")\n",
    "            print(f\"-------------------\")\n",
    "            print(f\"dimension : {self.img.ndim}\")\n",
    "            print(f\"shape     : {self.img.shape}\")\n",
    "            print(f\"NaNs      : {np.any(np.isnan(self.img))}\")\n",
    "            print(f\"mean      : {np.nanmean(self.img)}\")\n",
    "            print(f\"std       : {np.nanstd(self.img)}\")\n",
    "            print(f\"min       : {np.nanmin(self.img)}\")\n",
    "            print(f\"max       : {np.nanmax(self.img)}\")\n",
    "            print(f\"kurtosis  : {scs.kurtosis(self.img.flatten(), fisher=True, nan_policy='omit')}\")\n",
    "            print(f\"skewness  : {scs.skew(self.img.flatten(), nan_policy='omit')}\")\n",
    "            print(f\"C_inf     : {cinfinity(self.img)}\")\n",
    "\n",
    "        else:\n",
    "            with open(os.path.join(self.outfolder, f\"{os.path.basename(self.path)}.txt\"), \"w\") as file:\n",
    "                file.write(f\"Data description :\\n\")\n",
    "                file.write(f\"------------------\\n\")\n",
    "                file.write(f\"dimension : {self.data.ndim}\\n\")\n",
    "                file.write(f\"shape     : {self.data.shape}\\n\")\n",
    "                file.write(f\"NaNs      : {np.any(np.isnan(self.data))}\\n\")\n",
    "                file.write(f\"mean      : {np.nanmean(self.data)}\\n\")\n",
    "                file.write(f\"std       : {np.nanstd(self.data)}\\n\")\n",
    "                file.write(f\"min       : {np.nanmin(self.data)}\\n\")\n",
    "                file.write(f\"max       : {np.nanmax(self.data)}\\n\")\n",
    "                file.write(f\"kurtosis  : {scs.kurtosis(self.data.flatten(), fisher=True, nan_policy='omit')}\\n\")\n",
    "                file.write(f\"skewness  : {scs.skew(self.data.flatten(), nan_policy='omit')}\\n\")\n",
    "                file.write(f\"C_inf     : {cinfinity(self.data)}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "                file.write(f\"Image description :\\n\")\n",
    "                file.write(f\"-------------------\\n\")\n",
    "                file.write(f\"dimension : {self.img.ndim}\\n\")\n",
    "                file.write(f\"shape     : {self.img.shape}\\n\")\n",
    "                file.write(f\"NaNs      : {np.any(np.isnan(self.img))}\\n\")\n",
    "                file.write(f\"mean      : {np.nanmean(self.img)}\\n\")\n",
    "                file.write(f\"std       : {np.nanstd(self.img)}\\n\")\n",
    "                file.write(f\"min       : {np.nanmin(self.img)}\\n\")\n",
    "                file.write(f\"max       : {np.nanmax(self.img)}\\n\")\n",
    "                file.write(f\"kurtosis  : {scs.kurtosis(self.img.flatten(), fisher=True, nan_policy='omit')}\\n\")\n",
    "                file.write(f\"skewness  : {scs.skew(self.img.flatten(), nan_policy='omit')}\\n\")\n",
    "                file.write(f\"C_inf     : {cinfinity(self.img)}\\n\")\n",
    "        return\n",
    "\n",
    "\n",
    "    def plot_data(self, path=\"\"):\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        axe = fig.add_subplot(1,1,1)\n",
    "        axe.axis(\"equal\")\n",
    "        axe.imshow(self.data, origin=\"lower\")\n",
    "        axe.set_title(f\"{os.path.basename(self.path)} - données brutes\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "        \n",
    "        if path == \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(f\"{path}/donnees.jpg\")\n",
    "\n",
    "        plt.close()\n",
    "        return\n",
    "    \n",
    "\n",
    "    def plot_img(self):\n",
    "        \"\"\"\n",
    "        Produit l'image au format .jpg de l'image obtenue après pré-traitement des données.\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        axe = fig.add_subplot(1,1,1)\n",
    "        axe.axis(\"equal\")\n",
    "        axe.imshow(np.log(self.img), origin=\"lower\")\n",
    "        axe.set_title(f\"{os.path.basename(self.path)} - données pré-traitées ($\\log$)\")\n",
    "        axe.set_xlabel(\"X [px]\")\n",
    "        axe.set_ylabel(\"Y [px]\")\n",
    "        \n",
    "        if self.outfolder== \"\":\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(f\"{self.outfolder}/image.jpg\")\n",
    "\n",
    "        plt.close()\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation d'une simulation numérique effectuée avec ADELI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le post-traitement d'une expérience se fait à partir de la lecture des deux fichiers `t` et `p`, le premier contient le nombre de pas de temps, qui est un paramètre d'entrée de la lecture du fichier `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tfile():\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        return\n",
    "\n",
    "\n",
    "    def read(self) -> np.ndarray:\n",
    "        dates = None\n",
    "\n",
    "        try:\n",
    "            dates = np.genfromtxt(self.path)\n",
    "            dates = dates[:, 1]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        return dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi la classe `Tfile` ne contient qu'un chemin et a pour seule méthode l'extraction des valeurs des dates de sortie, dimensionnées. Le nombre d'éléments du vecteur renvoyé par la méthode `Tfile.read()` étant le nombre de dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pfile():\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.__read_header()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def __read_header(self) -> None:\n",
    "\n",
    "        fields   = []\n",
    "        topology = []\n",
    "\n",
    "        try:\n",
    "            with open(self.path, \"r\") as stream:\n",
    "                \n",
    "                # Read fields related informations\n",
    "                number = int(stream.readline().strip())\n",
    "                for _ in range(number):\n",
    "                    fields.append(stream.readline().strip())\n",
    "\n",
    "                # Read topology related informations\n",
    "                next(stream)\n",
    "                topology = np.int_(list(filter(None, stream.readline().strip().split(\" \"))))\n",
    "\n",
    "                # Update object attributes\n",
    "                self.nfields = len(fields)\n",
    "                self.fields  = fields\n",
    "\n",
    "                self.nelem = topology[0]\n",
    "                self.nvert = topology[1]\n",
    "                self.ngaus = topology[2]\n",
    "                self.ndime = topology[3]\n",
    "                self.nface = topology[4]\n",
    "                self.npres = topology[5]\n",
    "\n",
    "                self.offset = 1 +self.nfields +3 +self.nelem +1 +(self.npres//10 +1) +1 +self.nface +2\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def read_elements(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Lit la table de connectivité des noeuds du maillage.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        elements : np.ndarray\n",
    "                   conteneur de taille (nombre d'elements x 5), respectivement index du materiau, puis quatre indices de noeuds.\n",
    "        \"\"\"\n",
    "        elements = None\n",
    "\n",
    "        try:\n",
    "            elements = np.loadtxt( self.path,\n",
    "                                   dtype=int,\n",
    "                                   skiprows=(4 +self.nfields),\n",
    "                                   max_rows=self.nelem )\n",
    "            elements = elements[:, 1:]\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        return elements\n",
    "    \n",
    "\n",
    "    def read_contour(self) -> np.ndarray:\n",
    "        # contour = None\n",
    "\n",
    "        # try:\n",
    "        #     contour = np.genfromtxt( self.path,\n",
    "        #                               dtype=int,\n",
    "        #                               skip_header=(4 +self.nfields +self.nelem +1),\n",
    "        #                               skip_footer=(self.npres//10 +1) )\n",
    "        #     contour = contour.flatten()\n",
    "\n",
    "        # except FileNotFoundError:\n",
    "        #     print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        # return contour\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def read_faces(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Lit les \n",
    "        \"\"\"\n",
    "        faces = None\n",
    "\n",
    "        try:\n",
    "            faces = np.loadtxt( self.path,\n",
    "                                dtype=int,\n",
    "                                skiprows=(4 +self.nfields +self.nelem +1 +int(self.npres//10 +1) +1),\n",
    "                                max_rows=self.nface )\n",
    "            faces = faces[:, 1:]\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        return faces\n",
    "    \n",
    "\n",
    "    def read_coords(self, dates: list, names: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Lit les coordonnées, i.e les grandeurs nodales, de la simulation.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        dates : list[int]\n",
    "                liste d'entiers naturels correspondant aux index des dates.\n",
    "        names : list[str]\n",
    "                liste de noms de coordonnées tels que définis dans le script fortran extrac3d_ascii_plus_peierls.f.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        coords : np.ndarray\n",
    "                 valeurs des coordonnées lues ; coords[i, j, k] est la coordonnée names[j] au noeud k au temps dates[i].\n",
    "        \"\"\"\n",
    "        coords = np.zeros((len(dates), len(names), self.nvert)) *float('nan')\n",
    "\n",
    "        coordsmap = { 'x' : 1, 'y' : 2, 'z' : 3,\n",
    "                      'vx': 4, 'vy': 5, 'vz': 6,\n",
    "                      'ux': 7, 'uy': 8, 'uz': 9,\n",
    "                      'T' : 10 }\n",
    "        \n",
    "        try:\n",
    "            for i, n in enumerate(dates):\n",
    "                coords[i, :, :] = np.loadtxt( self.path, \n",
    "                                              dtype=float,\n",
    "                                              skiprows=(self.offset +n*(self.nvert + self.nelem +3)),\n",
    "                                              max_rows=self.nvert,\n",
    "                                              usecols=[coordsmap[name] for name in names] ).transpose()\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        return coords\n",
    "    \n",
    "\n",
    "    def read_fields(self, dates: list, names: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Lit depuis le fichier de sortie d'ADELI les grandeurs élémentaires.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        dates : list[int]\n",
    "                liste d'entiers naturels correspondant aux index des dates.\n",
    "        names : list[str]\n",
    "                liste des noms des champs tels que définis dans le script fortran 77 extrac3d_ascii_plus_peierls.f\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        fields : np.ndarray\n",
    "                 fields[i, j, k] est la valeur du champs names[j] évalué sur l'élément k au temps dates[i]\n",
    "        \"\"\"\n",
    "        fields = np.zeros((len(dates), len(names), self.nelem)) *float('nan')\n",
    "\n",
    "        fieldsmap = dict(\n",
    "            zip(\n",
    "                    [name for name in self.fields],\n",
    "                    [self.fields.index(name)+1 for name in self.fields] \n",
    "               )\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for i, n in enumerate(dates):\n",
    "                fields[i, :, :] = np.loadtxt( self.path,\n",
    "                                              dtype=float,\n",
    "                                              skiprows=(self.offset +n*(self.nelem +3) +(n+1)*self.nvert),\n",
    "                                              max_rows=self.nelem,\n",
    "                                              usecols=[fieldsmap[name] for name in names] ).transpose()\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"{self.path} is not readable, skip.\")\n",
    "\n",
    "        return fields"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe `Pfile` représente le fichier `p` d'une simulation par son chemin d'accès. Ses méthodes sont multiples et renvoient à la diversité des informations qu'on peut trouver dans le fichier, en particulier on y lit :\n",
    "\n",
    "- `Pfile.__read_header()` est une méthode privée qui permet l'accès aux informations nécessaires à la bonne lecture du fichier.\n",
    "\n",
    "Les méthodes publiques sont :\n",
    "\n",
    "- `Pfile.read_elements()`\n",
    "- `Pfile.read_contour()`\n",
    "- `Pfile.read_faces()`\n",
    "\n",
    "Ces trois fonctions sont les fonctions de base permettant de reconstruire la géométrie du domaine étudié. En fait, elles représentent la *topologie* du maillage permettant de reconstruire, à chaque pas de temps, la géométrie du domaine.\n",
    "\n",
    "- `Pfile.read_coords()`\n",
    "\n",
    "permet d'accéder aux valeurs nodales des objets de la simulation. Les coordonnées des points du maillage en font partie, ainsi que la vitesse, le déplacement et la température.\n",
    "\n",
    "- `Pfile.read_fields()`\n",
    "\n",
    "renvoie quant à elle les valeurs des champs physiques ou de leurs coordonnées. Ce sont des champs tensoriels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux classes `ScalarField` et `TensorField` viennent représenter les deux cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarField():\n",
    "\n",
    "    def __init__(self, name: str, dates: np.ndarray, mesh: list, values: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Constructeur.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        name   : str\n",
    "                 Nom du champ, utilisé dans les descriptions.\n",
    "        dates  : np.ndarray\n",
    "                 Vecteur des dates dimensionnées.\n",
    "        mesh   : list\n",
    "                 Liste des maillages de type tri.Triangulation.\n",
    "        values : np.ndarray\n",
    "                 values[k, i] représente la valeur du champ au k-ème instant, sur l'élément dont l'indexe est i.\n",
    "        \"\"\"\n",
    "        self.name   = name\n",
    "        self.dates  = dates\n",
    "        self.idates = list(range(len(dates)))\n",
    "        self.mesh   = mesh\n",
    "        self.values = values\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "    def describe(self, outfolder: str = \"\") -> None:\n",
    "\n",
    "        description = \\\n",
    "f\"\"\"Informations :\n",
    "--------------\n",
    "name  : {self.name}\n",
    "shape : {self.values.shape}\n",
    "NaNs  : {np.any(np.isnan(self.values))}\n",
    "\"\"\"\n",
    "        for k, d in enumerate(self.dates):\n",
    "            description += \"\\n\"\n",
    "            description += \\\n",
    "f\"\"\"Temps {d} - {self.dates[k]} [an]\n",
    "--------\n",
    "min      : {np.nanmin(self.values[k])}\n",
    "max      : {np.nanmax(self.values[k])}\n",
    "mean     : {np.nanmean(self.values[k])}\n",
    "std      : {np.nanstd(self.values[k])}\n",
    "skew     : {scs.skew(self.values[k], nan_policy='omit')}\n",
    "kurtosis : {scs.kurtosis(self.values[k], fisher=True, nan_policy='omit')}\n",
    "\"\"\"\n",
    "\n",
    "        if outfolder == \"\":\n",
    "            print(description)\n",
    "        else:\n",
    "            with open(f\"{outfolder}/{self.name}_description.txt\", \"w\") as buffer:\n",
    "                buffer.write(description)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "    def interpolate(self) -> None:\n",
    "        \"\"\"\n",
    "        Construit les attributs `grid` et `pict` de l'objet.\n",
    "        \"\"\"\n",
    "        nt, nel = self.values.shape\n",
    "\n",
    "        for n in nt:\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant implémenter la classe `Simulation`, toute l'information liée à une simulation se trouve en principe dans un unique dossier, on peut donc la représenter par le chemin de ce dossier. Dans le cadre de ce projet, il ne s'agit que de post-traiter une simulation ADELI qui a déjà abouti, on ne s'intéresse donc qu'aux deux fichiers `t` et `p`. On peut facilement travailler sur cette classe pour y inclure les autres fichiers afin de paramétrer voire de gérer complètement les simulations numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation():\n",
    "\n",
    "    def __init__(self, inpath: str, scalar=['Peierls', 'Work', 'WorkRate'], tensor=['d', 'e', 's']):\n",
    "        \"\"\"\n",
    "        Constructeur.\n",
    "        \"\"\"\n",
    "        self.path  = inpath\n",
    "        self.pfile = Pfile(os.path.join(self.path, \"\".join([filename for filename in os.listdir(self.path) if filename.startswith(\"p\")])))\n",
    "        self.tfile = Tfile(os.path.join(self.path, \"\".join([filename for filename in os.listdir(self.path) if filename.startswith(\"t\")])))\n",
    "        \n",
    "        self.dates  = self.tfile.read()\n",
    "        self.scalar = scalar\n",
    "        self.tensor = tensor\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheovolution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
